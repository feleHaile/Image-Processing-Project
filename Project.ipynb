{
 "cells": [],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}

# --- / / ---

#Seting the directory for the images 
dir_zip_files = 'D:\Python\Jupyter\IP_Project\zipFiles'
dir_unzip_files = 'D:\Python\Jupyter\IP_Project\DataBase'

#Seting the directory for the Metadata
dir_MetaData_zip_files = 'D:\Python\Jupyter\IP_Project\metaDataZipFile'
dir_MetaData_unzip_files = 'D:\Python\Jupyter\IP_Project\metaData_dataBase'

# --- / / ---

# Importing the packages
import os, zipfile # Extract files from a zip file
# ---
import csv
# ---
import numpy as np
import pandas as pd
import sys
import imageio
import glob
# ---
from os import listdir
from os.path import isfile, join
import numpy as np
import imageio
# --- 
import imageio
import matplotlib.pyplot as plt
# ---
import scipy.ndimage as ndi
# ---
from skimage.color import rgb2gray
import skimage.io as io
# ---
from skimage import data, color
from skimage.transform import rescale, resize, downscale_local_mean
# ---
from PIL import Image
import os
import sys
from skimage import color

# --- / / ---

#Extracting All Files From the Ziz File
extension = ".zip"
os.chdir(dir_zip_files) # change directory from working dir to dir with files

# Loop to extract all files from a the zip file on directory
for item in os.listdir(dir_zip_files): # loop through items in dir
    if item.endswith(extension): # check for ".zip" extension
        file_name = os.path.abspath(item) # get full path of files
        zip_ref = zipfile.ZipFile(file_name) # create zipfile object
        os.chdir(dir_zip_files) # change directory from working dir to dir with files
        zip_ref.extractall(dir_unzip_files) # extract file to dir
        zip_ref.close() # close file
        #os.remove(file_name) # delete zipped file

# --- / / ---

#Extract Metadata from all Images
os.chdir('D:\Python\Jupyter\IP_Project')

extension = ".zip"

os.chdir(dir_MetaData_zip_files) # change directory from working dir to dir with files

for item in os.listdir(dir_MetaData_zip_files): # loop through items in dir
    if item.endswith(extension): # check for ".zip" extension
        file_name = os.path.abspath(item) # get full path of files
        zip_ref = zipfile.ZipFile(file_name) # create zipfile object
        os.chdir(dir_MetaData_zip_files) # change directory from working dir to dir with files
        zip_ref.extractall(dir_MetaData_unzip_files) # extract file to dir
        zip_ref.close() # close file
        #os.remove(file_name) # delete zipped file   

# --- / / ---

# Read the MetaData
os.chdir(dir_MetaData_unzip_files) #change directory from working dir to dir with files

# Reading csv to pandas dataframe
metadata = pd.read_csv('HAM10000_metadata.csv')
#print(type(metadata))
#metadata.head()

# --- / / ---

# Reading the the file names of the each image
filenames = [os.path.splitext(filename)[0] for filename in os.listdir(dir_unzip_files)]
#len(filenames)
filenames = pd.DataFrame(np.array(filenames).reshape(10015,1),columns=['filenames'])
#print(type(filenames))

# --- / / ---

# Merging the file names and the metadata, thus organizing the data.
organized_metadata = pd.merge(left=filenames, right=metadata, left_on='filenames',right_on='image_id')

# --- / / ---

# Decreasing the size of images (Resize and Grayscale)
# From 600X450 to 200X150
path = dir_unzip_files
dirs = os.listdir( path )

for file_name in os.listdir(path):
  print("Processing %s" % file_name)
  image = Image.open(os.path.join(path, file_name))

  x,y = image.size
  new_dimensions = (200, 150)
  output = image.resize(new_dimensions, Image.ANTIALIAS).convert('LA')

  output_file_name = os.path.join(path, "grayscaleResized_" + file_name)
  output.save(output_file_name, "png", quality = 95)

# --- / / ---

# Reading all treated images into a Image Collection (Skimage package)
images = io.ImageCollection('D:\Python\Jupyter\IP_Project\DataBase\grayscaleResized_*', conserve_memory=True, load_func=None)
# Transforming the 'Image Colection' into a numpy array.
images = io.concatenate_images(images)

# --- / / ---

# Saving the image vector into a csv file (backup)
import numpy as np
from tempfile import TemporaryFile
vectors = TemporaryFile()
np.save(vectors, images)
np.save('vectors.npy', images)

# --- / / ---

# Creating one-hot encoding 

# Labels
labels = np.array(organized_metadata['dx'].tolist())
#print(type(labels))

# Classes
classes = np.array(["akiec","bcc","bkl","df","mel","nv","vasc"])
n_classes = len(classes)

# Initialize ohe_labels as all zeros
ohe_labels = np.zeros((len(labels), n_classes))

# Loop over the labels
for ii in range(len(labels)):
    # Find the location of this label in the categories variable
    jj = np.where(classes == labels[ii])
    # Set the corresponding zero to one
    ohe_labels[ii, jj] = 1

# --------------------- / / ---------------------------

# Trying to create the first CNN (Just to test)

# Imports components from Keras
from keras.models import Sequential
from keras.layers import Dense

# Initializes a sequential model
model = Sequential()

# First layer
model.add(Dense(10, activation='relu', input_shape=(120000,)))

# Second layer
model.add(Dense(10, activation='relu'))

# Output layer
model.add(Dense(7, activation='softmax'))

# --- / / ---

# Compile the model
model.compile(optimizer='adam', 
           loss='categorical_crossentropy', 
           metrics=['accuracy'])

# --- / / ---

train_data = images.reshape(10015, 120000)

# --- / / ---

# Fitting the model
model.fit(train_data, ohe_labels,
         validation_split=0.2,
         epochs=3)



